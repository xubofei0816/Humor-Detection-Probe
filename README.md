# Conflict Classification via a Probe based on a Pretrained LLM, A Subtask of Humor Detection
ANLP 2023 Final Project Report

# Introduction
You hear something funny, you laugh. Although, you won’t sit there, judge the material, and go "Oh it has the necessary components A, B, and C. Therefore, it qualifies as a funny joke. I should laugh. Hahaha!!". There must exist certain linguis- tic structures or characteristics in the material that stimulated our brain, such that our synapses would fire up, and our laughter would burst out. What are these structures and components? Numerous researchers have proposed linguistic models that attempt to answer this question. How do machines determine if a text is funny? Previous researchers have put forth many humor detection machines, such as the transformer based classifier by Weller and Seppi (2019), and the multimodal contexual extension of Memory Fusion Network (C-MFN) by Hasan et al. (2019). One of the ability of Neural Network based models is to extract implicit fea- tures in the form of the activation vectors in the hidden layers. While the classifiers are able to dis- tinguish humorous texts from non-humorous texts, do they adhere to a certain linguistic model that, researchers believe, human brains do? This paper aims to answer part of that question.
The first step of this study was to establish how human brains works, for which we resorted to hu- mor linguistic theories. Within the framework of the reviewed humor linguistic theories, we speci- fied the probing task as a sub-task of humor detec- tion, which we refer to as conflict-type classifica- tion. We will discuss this in the following sections in more details.
We trained the probe using the GridLoc method (Niu et al. (2022)), which outputs weights assigned to each token. We performed statistic testings, in- cluding the Mann-Whitney U test, and the Bi-serial test on the weights to test our hypothesis on the distributional differences between different group of tokens, as well as the correlation between the weights and the binary importance as labeled by the annotators.
# Related Work
In this section, we presented the related works by previous researchers. The literature review focused on both the linguistic humor theories, as well as the probing techniques.
## Linguistic Humor Model - Incongruity Resolution
The incongruity-resolution theory of humor is	widely advocated for, and is the basis of many variants. Due to the lack of standard terminologies, and the inherent difficulty in the definition	of incongruity, many variants of the IR model exist, out of which two of the more clearly defined (Ritchie (1999)) are the surprise disambiguation	model (as summarized by Ritchie of notions contained in Shultz (1974), Minsky (1984), and Paulos (1980)), and the two-stage model (Suls (1972)).
### Surprise Disambiguation 
For the SD model, Ritchie proposed that a humorous text include three entities M1, "the first (more	obvious) interpretation of the set-up", M2, "the second (hidden) interpretation of the set-up", and M3 "the meaning of the punchline", as well as five interrelations/properties of these entities, obviousness,	"M1 is more likely than M2 to be noticed by the reader", conflict, "M3 does not make sense with	M1", compatibility, "M3 does make sense with M2", comparison, "there is some contrasted relationship, even a clash between M1 and M2." , and inappropriateness, "M2 is inherently odd, eccentric,	or preposterous, or is taboo."
### Suls’ Two-Stage Model
As summarized by Ritchie (1999), the two-stage process the text with the follow procedure: The reader predict the next words given the read words. When no conflict is encountered with the reader’s prediction, the reader keep going. When a conflict is encountered, if the text is not ended, the reader will be puzzled. If the text is ended, then further, if the reader can find a cognitive rule that resolves the conflict then humor is found, otherwise the reader is also left in puzzlement.
## Probing
Probing is an approach used to study the internal representations of Neural Networks. With a pretrained neural-network based humor classifier (or a classifier trained for a even more generous purpose), or in another word a pretained encoder, we plan to use probing to to measure whether the characteristic linguistic structures of humorous texts are captured in the implicit features extracted by the encoder. Tenny et al. (Tenny et al. (2019)) employed the "edge probing" method combined with eight established probing tasks (Conneau et al. (2018)). They used te scalar mixing technique (Peters et al. (2018)) to pool the activation vectors, or under NLP setting the contextualized token embeddings, at the internal hidden layers of the encoder, as well as the original non-contextualized token embedding vectors. Then the resulted "weighted average" of these vectors (or the pooled vectors) are used to make prediction by the probing classifiers. The original encoding are not changed, which means when training the probing classifiers only the scalar parameters including the weights for each hidden layers, and a overall scaling parameter, were learned, not the parameters of the pretrained encoder. This is to ensure that the neural network won’t have just simply learned the probing task by modification of its encoding, but, again, have already included this information in its encoding. 
This probing architecture was used by Tenny et al. (2019), not only to perform the probing tasks, but more importantly to show in which layers are the probing tasks solved, in the claim that BERT rediscovered the classical NLP pipeline (upstream layers accountable for surface tasks, then layers at intermediate depths for syntactic tasks, finally downstream layers for semantic tasks). However, in an reappraisal (Niu et al. (2022)) of this effort, the authors showed that "pseudo-cognitive appeals to layer depth may not be the preferable mode of explanation for BERT’s inner workings", by showing that the layer depths do not have strong statistical correlation to the type of probing tasks. Given the controversy and our different aim than Tenny et al. (2019), we do not emphasize in which layers are	129 the information stored but rather focus on the existence of it. Niu et al. (2022) used an alternative "GridLoc" probing architecture, which not only assign attention weights to the hidden layers, but also dynamically assign attention weights to tokens. This allowed the analyses of the token importance in solving a probing task. This is significant to us for reason that will become clear in later sections. Therefore we plan to perform experiments using the GridLoc probing technique.
# Formalization of the Probing Task	
Within the surprise disambiguation model, there are two types of conflicts. The first type is the conflict between the punchline and the first more obvious interpretation of the set up. The second type is the conflict between the punchline and other more natural/expected predictions made by the viewer given the set-up.
An example of a joke containing the first type of conflict:
>•	"Why do birds fly south in winter? It’s too far to walk." Ritchie (1999)<

